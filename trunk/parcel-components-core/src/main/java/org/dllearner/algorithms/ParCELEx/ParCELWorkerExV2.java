package org.dllearner.algorithms.ParCELEx;

import java.util.HashSet;


import java.util.Map;
import java.util.Set;
import java.util.TreeSet;


import org.apache.log4j.Logger;
import org.dllearner.algorithms.ParCEL.ParCELEvaluationResult;
import org.dllearner.algorithms.ParCEL.ParCELExtraNode;
import org.dllearner.algorithms.ParCEL.ParCELNode;
import org.dllearner.algorithms.ParCEL.ParCELPosNegLP;
import org.dllearner.algorithms.ParCEL.ParCELRefinementOperatorPool;
import org.dllearner.algorithms.ParCEL.ParCELStringUtilities;
import org.dllearner.core.owl.Description;
import org.dllearner.core.owl.Negation;
import org.dllearner.refinementoperators.RefinementOperator;


/**
 * Worker class which will do the refinement on the given nodes and 
 * 	evaluate the refinement result. It will return partial definitions  
 * 	and/or new description to the reducer if any.   
 * 
 * This worker uses Online Combination strategy, i.e. it combine refinements with current 
 * 	counter partial definition set to create more cpdef
 * 
 * @author actran
 *
 */
public class ParCELWorkerExV2 implements Runnable {

	//name of worker (for debugging purpose)	
	private String name;

	//refinement operator used in refinement
	private ParCELRefinementOperatorPool refinementOperatorPool;
	private RefinementOperator refinementOperator;
	
	//reducer, used to make the callback to pass the result and get the next description for processing
	private ParCELearnerExV2 learner;
 
	//learning proble, provides accuracy & correctness calculation
	private ParCELPosNegLP learningProblem;	


	//the node to be processed
	private ParCELNode nodeToProcess;

	private Logger logger = Logger.getLogger(ParCELWorkerExV2.class);

	//these properties can be referred in Reducer. However, we put it here for faster access
	private String baseURI;
	private Map<String, String> prefix;


	/**=========================================================================================================<br>
	 * Constructor for Worker class. A worker needs the following things: 
	 * 		i) reducer (reference), ii) refinement operator, iii) start description, iv) worker name
	 *  
	 * @param reducer A reference to reducer which will be used to make a callback to return the result to
	 * @param refinementOperator Refinement operator used to refine the given node 
	 * @param learningProblem A learning problem used to calculate description accuracy, correctness, etc.
	 * @param nodeToProcess Node will being processed
	 * @param name Name of the worker, assigned by reduce (for tracing purpose only)
	 */
	public ParCELWorkerExV2(ParCELearnerExV2 reducer, ParCELRefinementOperatorPool refinementOperatorPool, 
			ParCELPosNegLP learningProblem, ParCELNode nodeToProcess, String name) {		

		super();

		this.learner = reducer;
		this.refinementOperatorPool = refinementOperatorPool;
		this.refinementOperator = null;

		this.learningProblem = learningProblem;

		this.nodeToProcess = nodeToProcess;
		this.name = name;

		this.baseURI = reducer.getBaseURI();
		this.prefix = reducer.getPrefix();	
	}

	
	
	/**=========================================================================================================<br>
	 * Constructor for Worker class. A worker needs the following things: 
	 * 		i) reducer (reference), ii) refinement operator, iii) start description, iv) worker name
	 *  
	 * @param reducer A reference to reducer which will be used to make a callback to return the result to
	 * @param refinementOperator Refinement operator used to refine the given node 
	 * @param learningProblem A learning problem used to calculate description accuracy, correctness, etc.
	 * @param nodeToProcess Node will being processed
	 * @param name Name of the worker, assigned by reduce (for tracing purpose only)
	 */
	public ParCELWorkerExV2(ParCELearnerExV2 reducer, RefinementOperator refinementOperator, 
			ParCELPosNegLP learningProblem, ParCELNode nodeToProcess, String name) {		

		super();

		this.learner = reducer;
		this.refinementOperator = refinementOperator;
		this.refinementOperatorPool = null;

		this.learningProblem = learningProblem;

		this.nodeToProcess = nodeToProcess;
		this.name = name;

		this.baseURI = reducer.getBaseURI();
		this.prefix = reducer.getPrefix();	
	}

	
	
	/**=========================================================================================================<br>
	 * Start the worker: Refine the given node and evaluate the refinements 
	 * <br>
	 * This method will call back the learner  to return:
	 * <ol>
	 * 	<li>New descriptions</li>
	 * 	<li>New partial definitions</li>
	 * 	<li>New counter partial definition</li>
	 * </ol>
	 * 
	 * NOTE: Partial definition generation time in this learner is used to represent the definition "type":
	 *  <br>
	 *  1: partial definitions that are generated directly by the refinement<br>
	 *  2: partial definitions that are generated by the combination of the descriptions in the search tree 
	 *  	and the counter partial definitions after the learning finishes 
	 *  3: partial definitions that are generated by the combination of new refinement and the counter partial definitions 
	 *  4: partial definitions that are generated by the combination of the input node and the counter partial definitions in the refinement
	 */
	@Override
	public void run() {
		
		if (logger.isTraceEnabled())
			logger.trace("[PLLearning] Processing node (" + ParCELStringUtilities.replaceString(nodeToProcess.toString(), this.baseURI, this.prefix));


		TreeSet<Description> refinements;	//will hold the refinement result (set of Descriptions)			
		
		HashSet<ParCELExtraNode> newPartialDefinitions = new HashSet<ParCELExtraNode>();	//hold the partial definitions if any
		HashSet<ParCELExtraNode> newCounterPartialDefinitions = new HashSet<ParCELExtraNode>();
		
		HashSet<ParCELNode> newNodes = new HashSet<ParCELNode>();	//hold the refinements that are not partial definitions
		
		int horizExp = nodeToProcess.getHorizontalExpansion();

		//1. refine node			
		refinements = refineNode(nodeToProcess);

		
		if (refinements != null) {
			if (logger.isTraceEnabled())
				logger.trace("[PLLearning] Refinement result (" + refinements.size() + "): " + 
						ParCELStringUtilities.replaceString(refinements.toString(), this.baseURI, this.prefix));
	
	
			//2. process the refinement result: calculate the accuracy and completeness and add the new expression into the search tree
			while (refinements.size() > 0) {	
				Description refinement = refinements.pollFirst();
				int refinementLength = refinement.getLength();
	
	
				// we ignore all refinements with lower length (may it happen?)
				// (this also avoids duplicate node children)
				if(refinementLength > horizExp) { 
	
					//calculate accuracy, correctness, positive examples covered by the description, resulted in a node
					ParCELExtraNode newNode = checkAndCreateNewNodeV2(refinement, nodeToProcess);
	
					//check for the type of new node: weak description, partial definition, counter partial definition or potential description
					if (newNode != null) {
	
						/*
						 *	- completeness(D) = 0, i.e. cp(D) = empty:
						 *		+ correctness(D) = 1, i.e. cn(D) = empty ==> weak description
						 *		+ correctness(D) < 1, i.e. cn(D) != empty ==> counter partial definition
						 *	- completeness(D) > 0, i.e. cp(D) != empty
						 *		+ correctness(D) = 1, i.e. cn(D) = empty ==> partial definition
						 *		+ correctness(D) < 1, i.e. cn(D) != empty ==> potential description 
						 */
						
						if (newNode.getCompleteness() == 0.0d) {
														
							//COUNTER PARTIAL DEFINITION: completeness=0 (cp=0) and correctness<1 (cn>0)
							//NOTE: Note that the counter partial will be return in the negative form
							if (newNode.getCorrectness() < 1d) {
								newNode.setType(ParCELExNodeTypes.COUNTER_PARTIAL_DEFINITION_UNUSED);	//0
								newNode.setGenerationTime(System.currentTimeMillis() - learner.getMiliStarttime());
								newNode.setDescription(new Negation(newNode.getDescription()));
								newCounterPartialDefinitions.add(newNode);							
							}
						}
						else {						
							//PARTIAL DEFINITION
							if (newNode.getCorrectness() == 1.0d) {
								newNode.setGenerationTime(System.currentTimeMillis() - learner.getMiliStarttime());
								newNode.setType(ParCELExNodeTypes.PARTIAL_DEFINITION_DIRECT_REFINED);	//1
								newPartialDefinitions.add(newNode);
							}
							//DESCRIPTION
							else {
								
								//check for the combination with the current counter partial definition set
								Set<ParCELExtraNode> combinableCounterPartialDefinitions = 
									ParCELExCombineCounterPartialDefinition.getCombinable(newNode, learner.getCurrentCounterPartialDefinitions());
								
								//PARTIAL DEFINITION
								//the new description may be combined with the counter partial definitions to become a partial definition
								if (combinableCounterPartialDefinitions != null) {	
									//for (ParCELExtraNode def : combinableCounterPartialDefinitions) {
										newNode.setDescription(ParCELExUtilities.createIntersection(newNode.getDescription(), 
												combinableCounterPartialDefinitions, true));										
										//def.setType(ParCELExNodeTypes.COUNTER_PARTIAL_DEFINITION_USED);	//2 - to mark the counter definition had been used to generate the partial definition
									//}
									
									//3 - means the partial definition is the result of the combination of a new refined description and a counter partial definition  
									newNode.setType(ParCELExNodeTypes.PARTIAL_DEFINITION_ONLINE_COMBINATION);	
									newNode.setGenerationTime(System.currentTimeMillis() - learner.getMiliStarttime());
									newPartialDefinitions.add(newNode);
								}
								else	//the new node cannot be combined ==> this is a DESCRIPTION  
									newNodes.add((ParCELNode)newNode);
							}
						}
					}	//if (node != null)
				}
			}	// while (refinements.size > 0)
			
			horizExp = nodeToProcess.getHorizontalExpansion();
			learner.updateMaxHorizontalExpansion(horizExp);
		}
		
		//process the input node: check if is it potentially a partial definition
		Set<ParCELExtraNode> combinableCounterPartialDefinitions = 
			ParCELExCombineCounterPartialDefinition.getCombinable(nodeToProcess, learner.getCurrentCounterPartialDefinitions());
				
		if (combinableCounterPartialDefinitions != null) {		
			//for (ParCELExtraNode def : combinableCounterPartialDefinitions)
				nodeToProcess.setDescription(ParCELExUtilities.createIntersection(
						nodeToProcess.getDescription(), combinableCounterPartialDefinitions, true));
			
			ParCELExtraNode newPD = new ParCELExtraNode(nodeToProcess);
			newPD.setGenerationTime(System.currentTimeMillis() - learner.getMiliStarttime());
			newPD.setType(ParCELExNodeTypes.PARTIAL_DEFINITION_REFINED_NODE);	//4 - (refined node + counter pdef) 
			newPartialDefinitions.add(newPD);
		}
		else
			newNodes.add(nodeToProcess);
		

		if (newPartialDefinitions.size() > 0)
			learner.newPartialDefinitionsFound(newPartialDefinitions);
		
		if (newCounterPartialDefinitions.size() > 0)
			learner.newCounterPartialDefinitionsFound(newCounterPartialDefinitions);

		learner.newRefinementDescriptions(newNodes);		//don't need to check for empty since newNodes is never empty 

	}



	/**=========================================================================================================<br>
	 * Refine a node using RhoDRDown. The refined node will be increased the max horizontal expansion value by 1
	 * 
	 * @param node Node to be refined
	 * 
	 * @return Set of descriptions that are the results of refinement  
	 */
	private TreeSet<Description> refineNode(ParCELNode node) {
		int horizExp = node.getHorizontalExpansion();

		if (logger.isTraceEnabled())
			logger.trace("[" + this.name + "] Refining: " + ParCELStringUtilities.replaceString(node.toString(), baseURI, prefix));
		
		boolean refirementOperatorBorrowed = false;
		
		//borrow refinement operator if necessary
		if (this.refinementOperator == null) {
			if (this.refinementOperatorPool == null) {
				logger.error("Neither refinement operator nor refinement operator pool provided");
				return null;
			} 
			else { 
				try {
					//logger.info("borrowing a refinement operator (" + refinementOperatorPool.getNumIdle() + ")");
					this.refinementOperator = this.refinementOperatorPool.borrowObject();
					refirementOperatorBorrowed = true;
				} catch (Exception e) {
					//e.printStackTrace();
				}
			}
		}
			
		TreeSet<Description> refinements = null;
		try {
			refinements = (TreeSet<Description>) refinementOperator.refine(node.getDescription(), horizExp+1);			
			node.incHorizontalExpansion();
			node.setRefinementCount(refinements.size());
		}
		catch (Exception e) {
			logger.error("Cannot refine: " + node.getDescription());
			return null;
		}

		
		//return the refinement operator
		if (refirementOperatorBorrowed) {
			try {
				if (refinementOperator != null)
					refinementOperatorPool.returnObject(refinementOperator);
				else
					logger.error("Cannot return the borrowed refinement operator");
			}
			catch (Exception e) {
				e.printStackTrace();
			}
		}
		
		return refinements;
	}
	
	
	/**
	 * ============================================================================================
	 * Calculate accuracy, correctness of a description and examples that are covered by this
	 * description<br>
	 * This version is used in the learning with exception
	 * 
	 * @param description
	 *            Description which is being calculated
	 * @param parentNode
	 *            The node which contains the description which is used in the refinement that
	 *            result the input description
	 * 
	 * @return Null if the description is processed before, or a node which contains the description
	 */
	private ParCELExtraNode checkAndCreateNewNodeV2(Description description, ParCELNode parentNode) {

		// redundancy check

		boolean nonRedundant = learner.addDescription(description);
		if (!nonRedundant)
			return null; // redundant, node cannot be added

		/**
		 * <ol>
		 * <li>cp(D) = empty</li>
		 * <ul>
		 * <li>cn(D) = empty: weak description ==> may be ignored</li>
		 * <li>cn(D) != empty: counter partial definition, especially used in learning with
		 * exceptions</li>
		 * </ul>
		 * <li>cp(D) != empty</li>
		 * <ul>
		 * <li>cn(D) = empty: partial definition</li>
		 * <li>cn(D) != empty: potential description</li>
		 * </ul>
		 * </ol>
		 */
		ParCELEvaluationResult evaluationResult = learningProblem.getAccuracyAndCorrectnessEx(description);

		// cover no positive example (completeness=0) && no negative example (correctness=1) 
		// ==> weak description
		if ((evaluationResult.getCompleteness() == 0) && (evaluationResult.getCorrectness() == 1))
			return null;

		ParCELExtraNode newNode = new ParCELExtraNode(parentNode, description,
				evaluationResult.getAccuracy(), evaluationResult.getCorrectness(),
				evaluationResult.getCompleteness(), evaluationResult.getCoveredPossitiveExamples(),
				evaluationResult.getCoveredNegativeExamples()); 

		// newNode.setCorrectness(evaluationResult.getCorrectness());
		// newNode.setCompleteness(evaluationResult.getCompleteness());
		// newNode.setCoveredPositiveExamples(evaluationResult.getCoveredPossitiveExamples());
		//newNode.setCoveredNegativeExamples(evaluationResult.getCoveredNegativeExamples());

		if (parentNode != null)
			parentNode.addChild(newNode);

		return newNode;

	} // addNode()



	/**
	 * Get the node which is currently being processed
	 * 
	 * @return The node currently being processed
	 */
	public ParCELNode getProcessingNode() {
		return this.nodeToProcess;
	}
}
